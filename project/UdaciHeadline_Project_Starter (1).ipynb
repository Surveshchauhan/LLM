{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "intro-header"
   },
   "source": [
    "# UdaciHeadline: LLM Inference Optimization Project\n",
    "\n",
    "## Project Introduction\n",
    "Large Language Models (LLMs) are transforming content creation, but deploying them efficiently remains a major hurdle. Imagine you're an ML Engineer at a bustling online news portal. Your key task? Automatically generating catchy headlines from article summaries using an LLM. The problem? The current inference process is sluggish, causing publication delays and driving up operational costs. In this project, UdaciHeadline, you'll step into this role and tackle this critical challenge head-on. Your mission is to accelerate the headline generation pipeline significantly by applying state-of-the-art LLM inference optimization techniques. Get ready to dive deep into practical optimization and deployment!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary-header"
   },
   "source": [
    "## Project Summary\n",
    "This project provides hands-on experience in optimizing the inference performance of a pre-trained Large Language Model (like Llama-3.2-1B) for news headline generation. You will bring together concepts of LLM architecture, optimization techniques, and deployment frameworks. Specifically, you will:\n",
    "\n",
    "1.  **Establish a baseline** inference pipeline and profile its performance.\n",
    "2.  Implement and evaluate architectural optimizations like **KV-caching**.\n",
    "3.  Apply model compression techniques like **quantization** and **pruning**.\n",
    "4.  Configure and benchmark **distributed inference** using Tensor and Pipeline Parallelism.\n",
    "5.  Apply advanced decoding mechanisms like **speculative decoding**.\n",
    "6.  Perform comprehensive **benchmarking and analysis** across all stages.\n",
    "7.  Produce a **final report** summarizing findings and trade-offs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports-header"
   },
   "source": [
    "## Imports and Global Configuration\n",
    "\n",
    "Let's import the libraries we'll use throughout the project and define some constants like the model name and the prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (25.2)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (80.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cmake\n",
      "  Downloading cmake-4.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.5 kB)\n",
      "Downloading cmake-4.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (29.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m206.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: cmake\n",
      "Successfully installed cmake-4.1.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install --upgrade cmake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting datasets>=2.0.0 (from evaluate)\n",
      "  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from evaluate) (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from evaluate) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from evaluate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from evaluate) (4.67.1)\n",
      "Collecting xxhash (from evaluate)\n",
      "  Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: multiprocess in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from evaluate) (0.70.18)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.9.0)\n",
      "Collecting huggingface-hub>=0.7.0 (from evaluate)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (21.0.0)\n",
      "Collecting httpx<1.0.0 (from datasets>=2.0.0->evaluate)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting multiprocess (from evaluate)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.13.0)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (2025.10.5)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0->datasets>=2.0.0->evaluate)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.7.0->evaluate)\n",
      "  Downloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->evaluate) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
      "Downloading datasets-4.3.0-py3-none-any.whl (506 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.1/566.1 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.10-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Downloading xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Installing collected packages: xxhash, multiprocess, httpcore, hf-xet, huggingface-hub, httpx, datasets, evaluate\n",
      "\u001b[2K  Attempting uninstall: multiprocess\n",
      "\u001b[2K    Found existing installation: multiprocess 0.70.18\n",
      "\u001b[2K    Uninstalling multiprocess-0.70.18:━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/8\u001b[0m [multiprocess]\n",
      "\u001b[2K      Successfully uninstalled multiprocess-0.70.18━━━━━━━━━━━\u001b[0m \u001b[32m1/8\u001b[0m [multiprocess]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8/8\u001b[0m [evaluate]6/8\u001b[0m [datasets]ce-hub]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.4 requires multiprocess>=0.70.18, but you have multiprocess 0.70.16 which is incompatible.\n",
      "sparkmagic 0.21.0 requires pandas<2.0.0,>=0.17.1, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-4.3.0 evaluate-0.4.6 hf-xet-1.1.10 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.36.0 multiprocess-0.70.16 xxhash-3.6.0\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (2.32.5)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->transformers) (2025.10.5)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m232.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.22.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m234.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Installing collected packages: safetensors, tokenizers, transformers\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/3\u001b[0m [transformers][0m [transformers]\n",
      "\u001b[1A\u001b[2KSuccessfully installed safetensors-0.6.2 tokenizers-0.22.1 transformers-4.57.1\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting absl-py (from rouge_score)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rouge_score) (3.9.2)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk->rouge_score) (8.3.0)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk->rouge_score) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk->rouge_score) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nltk->rouge_score) (4.67.1)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Building wheels for collected packages: rouge_score\n",
      "\u001b[33m  DEPRECATION: Building 'rouge_score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge_score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24987 sha256=2cc093bbc2232e057ea52d068bc085077e24753755e4aef2464a88a8f6ca315b\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: absl-py, rouge_score\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [rouge_score]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 rouge_score-0.1.2\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.48.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Collecting torch<3,>=2.3 (from bitsandbytes)\n",
      "  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from bitsandbytes) (24.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes) (2025.9.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.3->bitsandbytes)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.3->bitsandbytes)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.3->bitsandbytes)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.3->bitsandbytes)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.3->bitsandbytes)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.3->bitsandbytes)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.3->bitsandbytes)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.3->bitsandbytes)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.3->bitsandbytes)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch<3,>=2.3->bitsandbytes)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch<3,>=2.3->bitsandbytes)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch<3,>=2.3->bitsandbytes)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.3->bitsandbytes)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch<3,>=2.3->bitsandbytes)\n",
      "  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch<3,>=2.3->bitsandbytes)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy==1.13.1->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
      "Downloading bitsandbytes-0.48.1-py3-none-manylinux_2_24_x86_64.whl (60.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m145.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m145.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m133.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m122.4 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m135.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m171.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m193.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, bitsandbytes\n",
      "\u001b[2K  Attempting uninstall: sympy━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/17\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [sympy]parselt-cu12]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/17\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/17\u001b[0m [bitsandbytes][0m [bitsandbytes]er-cu12]2]\n",
      "\u001b[1A\u001b[2KSuccessfully installed bitsandbytes-0.48.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.6.0 triton-3.2.0\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from accelerate) (7.1.0)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.9.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.10)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.10.5)\n",
      "Downloading accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.11.0\n",
      "Requirement already satisfied: datasets in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (4.3.0)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.0)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.1.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "!pip install --upgrade transformers\n",
    "!pip install rouge_score\n",
    "!pip install bitsandbytes\n",
    "!pip install accelerate\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (3.19.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\n",
      "  Using cached pyarrow-21.0.0.tar.gz (1.1 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: dill<0.4.1,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (2.32.5)\n",
      "Collecting httpx<1.0.0 (from datasets)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (4.67.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.9.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (0.36.0)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohttp-3.13.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (2025.8.3)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0->datasets)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1.0.0->datasets) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.1.10)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets)\n",
      "  Using cached yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.19)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Using cached datasets-4.3.0-py3-none-any.whl (506 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "Using cached aiohttp-3.13.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "Using cached async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Using cached multidict-6.7.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (241 kB)\n",
      "Using cached yarl-1.22.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (346 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached frozenlist-1.8.0-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (219 kB)\n",
      "Using cached propcache-0.4.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (196 kB)\n",
      "Using cached xxhash-3.6.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)\n",
      "Building wheels for collected packages: pyarrow\n",
      "  Building wheel for pyarrow (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for pyarrow \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[881 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-re2ttajx/overlay/lib/python3.10/site-packages/setuptools/config/_apply_pyprojecttoml.py:82: SetuptoolsDeprecationWarning: `project.license` as a TOML table is deprecated\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please use a simple string containing a SPDX expression for `project.license`. You can also use `project.license-files`. (Both options available on setuptools>=77.0.0).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         By 2026-Feb-18, you need to update your project and remove deprecated calls\n",
      "  \u001b[31m   \u001b[0m         or your builds will no longer be supported.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   corresp(dist, value, root_dir)\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-re2ttajx/overlay/lib/python3.10/site-packages/setuptools/config/_apply_pyprojecttoml.py:61: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         License :: OSI Approved :: Apache Software License\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   dist._finalize_license_expression()\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-re2ttajx/overlay/lib/python3.10/site-packages/setuptools/dist.py:483: SetuptoolsDeprecationWarning: Pattern '../LICENSE.txt' cannot contain '..'\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please ensure the files specified are contained by the root\n",
      "  \u001b[31m   \u001b[0m         of the Python package (normally marked by `pyproject.toml`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         By 2026-Mar-20, you need to update your project and remove deprecated calls\n",
      "  \u001b[31m   \u001b[0m         or your builds will no longer be supported.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/specifications/glob-patterns/ for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   for path in sorted(cls._find_pattern(pattern, enforce_match))\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-re2ttajx/overlay/lib/python3.10/site-packages/setuptools/dist.py:483: SetuptoolsDeprecationWarning: Cannot find any files for the given pattern.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Pattern '../LICENSE.txt' did not match any files.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         By 2026-Mar-20, you need to update your project and remove deprecated calls\n",
      "  \u001b[31m   \u001b[0m         or your builds will no longer be supported.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   for path in sorted(cls._find_pattern(pattern, enforce_match))\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-re2ttajx/overlay/lib/python3.10/site-packages/setuptools/dist.py:483: SetuptoolsDeprecationWarning: Pattern '../NOTICE.txt' cannot contain '..'\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please ensure the files specified are contained by the root\n",
      "  \u001b[31m   \u001b[0m         of the Python package (normally marked by `pyproject.toml`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         By 2026-Mar-20, you need to update your project and remove deprecated calls\n",
      "  \u001b[31m   \u001b[0m         or your builds will no longer be supported.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/specifications/glob-patterns/ for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   for path in sorted(cls._find_pattern(pattern, enforce_match))\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-re2ttajx/overlay/lib/python3.10/site-packages/setuptools/dist.py:483: SetuptoolsDeprecationWarning: Cannot find any files for the given pattern.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Pattern '../NOTICE.txt' did not match any files.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         By 2026-Mar-20, you need to update your project and remove deprecated calls\n",
      "  \u001b[31m   \u001b[0m         or your builds will no longer be supported.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   for path in sorted(cls._find_pattern(pattern, enforce_match))\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-re2ttajx/overlay/lib/python3.10/site-packages/setuptools/dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         License :: OSI Approved :: Apache Software License\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   self._finalize_license_expression()\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/__init__.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_compute_docstrings.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_generated_version.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/acero.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/benchmark.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/cffi.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/compute.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/conftest.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/csv.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/cuda.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/dataset.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/feather.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/flight.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/fs.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/ipc.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/json.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/jvm.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/orc.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/pandas_compat.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/substrait.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/types.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/util.py -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m running egg_info\n",
      "  \u001b[31m   \u001b[0m writing pyarrow.egg-info/PKG-INFO\n",
      "  \u001b[31m   \u001b[0m writing dependency_links to pyarrow.egg-info/dependency_links.txt\n",
      "  \u001b[31m   \u001b[0m writing requirements to pyarrow.egg-info/requires.txt\n",
      "  \u001b[31m   \u001b[0m writing top-level names to pyarrow.egg-info/top_level.txt\n",
      "  \u001b[31m   \u001b[0m listing git files failed - pretending there aren't any\n",
      "  \u001b[31m   \u001b[0m reading manifest file 'pyarrow.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '../LICENSE.txt'\n",
      "  \u001b[31m   \u001b[0m warning: no files found matching '../NOTICE.txt'\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*.so' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '#*' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '.git*' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m warning: no previously-included files matching '.DS_Store' found anywhere in distribution\n",
      "  \u001b[31m   \u001b[0m no previously-included directories found matching '.asv'\n",
      "  \u001b[31m   \u001b[0m writing manifest file 'pyarrow.egg-info/SOURCES.txt'\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-re2ttajx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.includes' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.includes' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.includes' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.includes' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.includes' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-re2ttajx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.interchange' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.interchange' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.interchange' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.interchange' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.interchange' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-re2ttajx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.parquet' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.parquet' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.parquet' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.parquet' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.parquet' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-re2ttajx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.src.arrow.python' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.src.arrow.python' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.src.arrow.python' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.src.arrow.python' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.src.arrow.python' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-re2ttajx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.src.arrow.python.vendored' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.src.arrow.python.vendored' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.src.arrow.python.vendored' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.src.arrow.python.vendored' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.src.arrow.python.vendored' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-re2ttajx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-re2ttajx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.data.feather' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.data.feather' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.data.feather' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.data.feather' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.data.feather' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-re2ttajx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.data.orc' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.data.orc' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.data.orc' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.data.orc' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.data.orc' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-re2ttajx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.data.parquet' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.data.parquet' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.data.parquet' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.data.parquet' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.data.parquet' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-re2ttajx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.interchange' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.interchange' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.interchange' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.interchange' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.interchange' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-re2ttajx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.tests.parquet' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.tests.parquet' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.tests.parquet' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.tests.parquet' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.tests.parquet' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m /tmp/pip-build-env-re2ttajx/overlay/lib/python3.10/site-packages/setuptools/command/build_py.py:212: _Warning: Package 'pyarrow.vendored' is absent from the `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         # Package would be ignored #\n",
      "  \u001b[31m   \u001b[0m         ############################\n",
      "  \u001b[31m   \u001b[0m         Python recognizes 'pyarrow.vendored' as an importable package[^1],\n",
      "  \u001b[31m   \u001b[0m         but it is absent from setuptools' `packages` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         This leads to an ambiguous overall configuration. If you want to distribute this\n",
      "  \u001b[31m   \u001b[0m         package, please make sure that 'pyarrow.vendored' is explicitly added\n",
      "  \u001b[31m   \u001b[0m         to the `packages` configuration field.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         Alternatively, you can also rely on setuptools' discovery methods\n",
      "  \u001b[31m   \u001b[0m         (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "  \u001b[31m   \u001b[0m         instead of `find_packages(...)`/`find:`).\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package discovery\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/package_discovery.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         If you don't want 'pyarrow.vendored' to be distributed and are\n",
      "  \u001b[31m   \u001b[0m         already explicitly excluding 'pyarrow.vendored' via\n",
      "  \u001b[31m   \u001b[0m         `find_namespace_packages(...)/find_namespace` or `find_packages(...)/find`,\n",
      "  \u001b[31m   \u001b[0m         you can try to use `exclude_package_data`, or `include-package-data=False` in\n",
      "  \u001b[31m   \u001b[0m         combination with a more fine grained `package-data` configuration.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         You can read more about \"package data files\" on setuptools documentation page:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         - https://setuptools.pypa.io/en/latest/userguide/datafiles.html\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m         [^1]: For Python, any directory (with suitable naming) can be imported,\n",
      "  \u001b[31m   \u001b[0m               even if it does not contain any `.py` files.\n",
      "  \u001b[31m   \u001b[0m               On the other hand, currently there is no concept of package data\n",
      "  \u001b[31m   \u001b[0m               directory, all directories are treated like packages.\n",
      "  \u001b[31m   \u001b[0m         ********************************************************************************\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m !!\n",
      "  \u001b[31m   \u001b[0m   check.warn(importable)\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/__init__.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_acero.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_acero.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_azurefs.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_compute.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_compute.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_csv.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_csv.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_cuda.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_cuda.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset_orc.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset_parquet.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset_parquet.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dataset_parquet_encryption.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_dlpack.pxi -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_feather.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_flight.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_fs.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_fs.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_gcsfs.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_hdfs.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_json.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_json.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_orc.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_orc.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_parquet.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_parquet.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_parquet_encryption.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_parquet_encryption.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_pyarrow_cpp_tests.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_pyarrow_cpp_tests.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_s3fs.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/_substrait.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/array.pxi -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/benchmark.pxi -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/builder.pxi -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/compat.pxi -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/config.pxi -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/device.pxi -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/error.pxi -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/gandiva.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/io.pxi -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/ipc.pxi -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/lib.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/lib.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/memory.pxi -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/pandas-shim.pxi -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/public-api.pxi -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/scalar.pxi -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/table.pxi -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tensor.pxi -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/types.pxi -> build/lib.linux-x86_64-cpython-310/pyarrow\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/__init__.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/common.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_acero.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_cuda.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_dataset.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_dataset_parquet.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_feather.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_flight.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_fs.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_python.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libarrow_substrait.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libgandiva.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libparquet.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/includes/libparquet_encryption.pxd -> build/lib.linux-x86_64-cpython-310/pyarrow/includes\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/__init__.py -> build/lib.linux-x86_64-cpython-310/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/buffer.py -> build/lib.linux-x86_64-cpython-310/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/column.py -> build/lib.linux-x86_64-cpython-310/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/dataframe.py -> build/lib.linux-x86_64-cpython-310/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/interchange/from_dataframe.py -> build/lib.linux-x86_64-cpython-310/pyarrow/interchange\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pyarrow/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/parquet/__init__.py -> build/lib.linux-x86_64-cpython-310/pyarrow/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/parquet/core.py -> build/lib.linux-x86_64-cpython-310/pyarrow/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/parquet/encryption.py -> build/lib.linux-x86_64-cpython-310/pyarrow/parquet\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/CMakeLists.txt -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/api.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/arrow_to_pandas.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/arrow_to_pandas.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/arrow_to_python_internal.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/async.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/benchmark.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/benchmark.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/common.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/common.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/csv.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/csv.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/datetime.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/datetime.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/decimal.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/decimal.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/extension_type.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/extension_type.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/filesystem.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/filesystem.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/flight.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/flight.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/gdb.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/gdb.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/helpers.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/helpers.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/inference.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/inference.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/io.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/io.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/ipc.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/ipc.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/iterators.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_convert.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_convert.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_init.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_init.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_internal.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_interop.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_to_arrow.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/numpy_to_arrow.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/parquet_encryption.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/parquet_encryption.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/platform.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/pyarrow.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/pyarrow.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/pyarrow_api.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/pyarrow_lib.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/python_test.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/python_test.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/python_to_arrow.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/python_to_arrow.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/type_traits.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/udf.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/udf.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/util.cc -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/util.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/visibility.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/vendored/CMakeLists.txt -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/src/arrow/python/vendored/pythoncapi_compat.h -> build/lib.linux-x86_64-cpython-310/pyarrow/src/arrow/python/vendored\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/__init__.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/arrow_16597.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/arrow_39313.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/arrow_7980.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/bound_function_visit_strings.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/conftest.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/extensions.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/pandas_examples.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/pandas_threaded_import.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/pyarrow_cython_example.pyx -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/read_record_batch.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/strategies.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_acero.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_adhoc_memory_leak.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_array.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_builder.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cffi.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_compute.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_convert_builtin.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cpp_internals.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_csv.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cuda.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cuda_numba_interop.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_cython.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_dataset.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_dataset_encryption.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_deprecations.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_device.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_dlpack.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_exec_plan.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_extension_type.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_feather.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_flight.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_flight_async.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_fs.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_gandiva.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_gdb.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_io.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_ipc.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_json.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_jvm.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_memory.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_misc.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_orc.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_pandas.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_scalars.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_schema.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_sparse_tensor.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_strategies.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_substrait.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_table.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_tensor.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_types.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_udf.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_util.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/test_without_numpy.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/util.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/wsgi_examples.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pyarrow/tests/data/feather\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/feather/v0.17.0.version.2-compression.lz4.feather -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/data/feather\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/README.md -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.emptyFile.jsn.gz -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.emptyFile.orc -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.test1.jsn.gz -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.test1.orc -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.testDate1900.jsn.gz -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/TestOrcFile.testDate1900.orc -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/decimal.jsn.gz -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/orc/decimal.orc -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/data/orc\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/parquet/v0.7.1.all-named-index.parquet -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/parquet/v0.7.1.column-metadata-handling.parquet -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/parquet/v0.7.1.parquet -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/data/parquet/v0.7.1.some-named-index.parquet -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/data/parquet\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pyarrow/tests/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/interchange/__init__.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/interchange/test_conversion.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/interchange\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/interchange/test_interchange_spec.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/interchange\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/__init__.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/common.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/conftest.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/encryption.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_basic.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_compliant_nested_type.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_data_types.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_dataset.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_datetime.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_encryption.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_metadata.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_pandas.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_parquet_file.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/tests/parquet/test_parquet_writer.py -> build/lib.linux-x86_64-cpython-310/pyarrow/tests/parquet\n",
      "  \u001b[31m   \u001b[0m creating build/lib.linux-x86_64-cpython-310/pyarrow/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/vendored/__init__.py -> build/lib.linux-x86_64-cpython-310/pyarrow/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/vendored/docscrape.py -> build/lib.linux-x86_64-cpython-310/pyarrow/vendored\n",
      "  \u001b[31m   \u001b[0m copying pyarrow/vendored/version.py -> build/lib.linux-x86_64-cpython-310/pyarrow/vendored\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m creating /tmp/pip-install-ra5pwqcl/pyarrow_69e01854d7da4d6dbd43feaf9a07c447/build/temp.linux-x86_64-cpython-310\n",
      "  \u001b[31m   \u001b[0m -- Running cmake for PyArrow\n",
      "  \u001b[31m   \u001b[0m cmake -DCMAKE_INSTALL_PREFIX=/tmp/pip-install-ra5pwqcl/pyarrow_69e01854d7da4d6dbd43feaf9a07c447/build/lib.linux-x86_64-cpython-310/pyarrow -DPYTHON_EXECUTABLE=/home/ec2-user/anaconda3/envs/pytorch_p310/bin/python3.10 -DPython3_EXECUTABLE=/home/ec2-user/anaconda3/envs/pytorch_p310/bin/python3.10 -DPYARROW_CXXFLAGS= -DPYARROW_BUNDLE_ARROW_CPP=off -DPYARROW_BUNDLE_CYTHON_CPP=off -DPYARROW_GENERATE_COVERAGE=off -DCMAKE_BUILD_TYPE=release /tmp/pip-install-ra5pwqcl/pyarrow_69e01854d7da4d6dbd43feaf9a07c447\n",
      "  \u001b[31m   \u001b[0m CMake Error at CMakeLists.txt:21 (cmake_minimum_required):\n",
      "  \u001b[31m   \u001b[0m   CMake 3.25 or higher is required.  You are running version 2.8.12.2\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m -- Configuring incomplete, errors occurred!\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/cmake' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for pyarrow\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25hFailed to build pyarrow\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mfailed-wheel-build-for-install\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Failed to build installable wheels for some pyproject.toml based projects\n",
      "\u001b[31m╰─>\u001b[0m pyarrow\n"
     ]
    }
   ],
   "source": [
    "# !pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "imports-code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from evaluate import load as load_metric\n",
    "\n",
    "from time import time as get_time\n",
    "from pprint import pprint\n",
    "import torch.nn.utils.prune as prune\n",
    "import copy\n",
    "#os.environ[\"HF_HUB_OFFLINE\"] = \"1\"\n",
    "# ---- Constants ----\n",
    "\n",
    "MODEL_NAME = \"meta-llama/Meta-Llama-3-1B\"\n",
    "MAX_NEW_TOKENS = 50 # Max length for the generated headline\n",
    "\n",
    "#PROMPT = \\\n",
    "# print(f\"Prompt: \\\"{PROMPT}\\\"\")\n",
    "TARGET_LAYER_NAME_STR = \"model.layers.0.mlp.gate_proj\"\n",
    "\n",
    "# We will prune 50% of the weights in this layer\n",
    "PRUNING_AMOUNT = 0.5 \n",
    "NUM_PREDICTION = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data-loading-header"
   },
   "source": [
    "## Data Loading\n",
    "\n",
    "We will use the \"News Category Dataset\" from Kaggle. The `kagglehub` library makes it easy to download and access. Your task is to implement the function to load and preprocess the data according to the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "data-loading-code"
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_news_dataset(path):\n",
    "    \"\"\"TODO: Implement the data loading and preprocessing logic here.\"\"\"\n",
    "    dataset = load_dataset(\"json\", data_files=path, split=\"train[:1000]\")\n",
    "    articles = [item[\"short_description\"] for item in dataset]\n",
    "\n",
    "    return dataset,articles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baseline-header"
   },
   "source": [
    "# 2. Baseline Performance\n",
    "\n",
    "Before we can optimize, we need a starting point. Here, you'll establish the baseline performance of the `Llama-3.2-1B` model without any specific optimizations. We will measure latency, throughput, and the quality of the generated headlines using the ROUGE score.\n",
    "\n",
    "### Your Task: Implement the Evaluation Pipeline\n",
    "You need to implement the core functions for loading a model, generating a headline, and evaluating performance. These functions will be reused for every optimization technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "baseline-helpers"
   },
   "outputs": [],
   "source": [
    "def load_model(model_name, quantization_config=None,device=\"cpu\"):\n",
    "    \"\"\"TODO: Implement the logic for loading a tokenizer and model.\"\"\"\n",
    "    \n",
    "    dtype = torch.bfloat16 if device == \"cuda\" and torch.cuda.is_bf16_supported() else torch.float32\n",
    "    print(f\"Using model: {model_name}\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(f\"Using dtype: {dtype}\")\n",
    "\n",
    "    print(\"Loading tokenizer...\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    print(\"Tokenizer loaded successfully.\")\n",
    "    print(\"Loading model...\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, dtype=\"auto\",quantization_config=quantization_config).to(device)\n",
    "    print(\"Model loaded successfully and moved to device.\")\n",
    "    model.eval()\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model.config.pad_token_id = model.config.eos_token_id\n",
    "\n",
    "    return model,tokenizer\n",
    "\n",
    "def generate_headline(model, tokenizer,texts,device,max_length,use_cache=False):\n",
    "    \"\"\"TODO: Implement the headline generation and latency measurement logic.\"\"\"\n",
    "    headlines = []\n",
    "    latencies = []\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "            start = get_time()\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_length,\n",
    "                use_cache=use_cache,  # Baseline: no KV caching\n",
    "                do_sample=False\n",
    "            )\n",
    "            end = get_time()\n",
    "            latencies.append(end - start)\n",
    "            headline = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            headlines.append(headline)\n",
    "    return headlines, latencies\n",
    "\n",
    "def report_metrics(times,section):#results, latencies, max_new_tokens):\n",
    "    \"\"\"TODO: Implement the logic for calculating and reporting all performance metrics.\"\"\"\n",
    "    avg_latency = sum(times) / len(times)\n",
    "    p99_latency = sorted(times)[int(0.99 * len(times))]\n",
    "    throughput = len(times) / sum(times)\n",
    "    gpu_memory = torch.cuda.max_memory_allocated() / (1024 ** 2)\n",
    "    print(f\"Below are for: {section}s\")\n",
    "    print(f\"Avg Latency: {avg_latency:.3f}s\")\n",
    "    print(f\"P99 Latency: {p99_latency:.3f}s\")\n",
    "    print(f\"Throughput: {throughput:.2f} samples/sec\")\n",
    "    print(f\"Max GPU Memory: {gpu_memory:.2f} MB\")\n",
    "\n",
    "    pass\n",
    "\n",
    "def evaluate_model(dataset,generated,num_prediction):\n",
    "    \"\"\"TODO: Implement the model evaluation loop.\"\"\"\n",
    "    rouge = load_metric(\"rouge\")\n",
    "    references = [item for item in dataset[:num_prediction]['headline']]\n",
    "    results = rouge.compute(predictions=generated, references=references)\n",
    "    print(\"ROUGE Scores:\", results)\n",
    "    \n",
    "    return results\n",
    "def clean(model,tokenizer):\n",
    "    # Clean up model from memory\n",
    "    del model\n",
    "    del tokenizer\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"\\nCleaned up models and emptied CUDA cache.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_module_by_name_str(model, module_name_str):\n",
    "    \"\"\"Gets a module from a model using its string name (e.g., 'model.layers.0.mlp.gate_proj').\"\"\"\n",
    "    names = module_name_str.split('.')\n",
    "    current_module = model\n",
    "    for name_part in names:\n",
    "        if hasattr(current_module, name_part):\n",
    "            current_module = getattr(current_module, name_part)\n",
    "        else:\n",
    "            try: # Handle numeric indices in ModuleLists\n",
    "                idx = int(name_part)\n",
    "                current_module = current_module[idx]\n",
    "            except (ValueError, TypeError, IndexError):\n",
    "                raise AttributeError(f\"Could not resolve name part '{name_part}' in '{module_name_str}'.\")\n",
    "    return current_module\n",
    "\n",
    "def calculate_sparsity(module, param_name='weight'):\n",
    "    \"\"\"Calculates sparsity of a named parameter in a module.\"\"\"\n",
    "    if hasattr(module, param_name):\n",
    "        param = getattr(module, param_name)\n",
    "        if param is not None:\n",
    "            return 100. * float(torch.sum(param == 0)) / float(param.nelement())\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "HF_TOKEN = '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'\n",
    "login(token=HF_TOKEN)\n",
    "datasets, articles = load_news_dataset(\"../dataset/News_Category_Dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "baseline-eval"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: meta-llama/Llama-3.2-1B\n",
      "Using device: cuda\n",
      "Using dtype: torch.bfloat16\n",
      "Loading tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0705ff8582e942ea8fcf8e85b5da5d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd568386877740ceab3bcd23186d00eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4f3e031c5049aeaa10c322d3e4d4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/301 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded successfully.\n",
      "Loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e626fc828a4b2c85562162b2a21619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211477ceeec646c2950718fed713bf38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d853e4025794af99baf6ac44254cbe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully and moved to device.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are for: Baselines\n",
      "Avg Latency: 3.823s\n",
      "P99 Latency: 4.207s\n",
      "Throughput: 0.26 samples/sec\n",
      "Max GPU Memory: 2373.51 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bcdc846c2744bcd8ac849406f72ec8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores: {'rouge1': 0.06223311470956908, 'rouge2': 0.0027027027027027024, 'rougeL': 0.04828548644338118, 'rougeLsum': 0.049484078622184645}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.06223311470956908,\n",
       " 'rouge2': 0.0027027027027027024,\n",
       " 'rougeL': 0.04828548644338118,\n",
       " 'rougeLsum': 0.049484078622184645}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Establish your baseline performance.\n",
    "\n",
    "dtype = torch.bfloat16 if device == \"cuda\" and torch.cuda.is_bf16_supported() else torch.float32\n",
    "model_new,tokenizer = load_model(model_name=model_name,quantization_config = None,device=device)\n",
    "sample_texts = articles[:NUM_PREDICTION]\n",
    "generated, times = generate_headline(model_new, tokenizer, sample_texts, device,MAX_NEW_TOKENS)\n",
    "report_metrics(times,\"Baseline\")\n",
    "evaluate_model(datasets,generated,NUM_PREDICTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kv-cache-header"
   },
   "source": [
    "# 3. Architectural Optimization: KV Caching\n",
    "\n",
    "**Your Task:** One of the most effective ways to speed up token generation is using a Key-Value (KV) cache. This avoids re-computing attention scores for tokens that are already part of the sequence. Enable the `use_cache` flag in the generation arguments and re-run the evaluation. Observe the impact on latency and throughput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kv-cache-code"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are for: KV Cachings\n",
      "Avg Latency: 1.094s\n",
      "P99 Latency: 1.117s\n",
      "Throughput: 0.91 samples/sec\n",
      "Max GPU Memory: 2373.51 MB\n",
      "ROUGE Scores: {'rouge1': 0.06440349178782798, 'rouge2': 0.0027027027027027024, 'rougeL': 0.04832239714195846, 'rougeLsum': 0.05169932288826383}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.06440349178782798,\n",
       " 'rouge2': 0.0027027027027027024,\n",
       " 'rougeL': 0.04832239714195846,\n",
       " 'rougeLsum': 0.05169932288826383}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Evaluate the model with KV Caching enabled.\n",
    "sample_texts = articles[:NUM_PREDICTION]\n",
    "generated, times = generate_headline(model_new, tokenizer, sample_texts, device,MAX_NEW_TOKENS,\"True\")\n",
    "report_metrics(times,\"KV Caching\")\n",
    "evaluate_model(datasets,generated,NUM_PREDICTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pruning-header"
   },
   "source": [
    "# 4. Model Compression: Pruning\n",
    "\n",
    "**Your Task:** Pruning removes redundant model weights, which can reduce model size and potentially speed up inference. Here, you will implement unstructured, magnitude-based pruning by creating a function that applies it to the model's linear layers and then evaluating the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pruning-code"
   },
   "outputs": [],
   "source": [
    "# def prune_model_weights(model, amount=0.3):\n",
    "#     \"\"\"TODO: Applies L1 unstructured pruning to the linear layers of a model.\"\"\"\n",
    "#     print(f\"\\n--- Accessing Target Layer: {TARGET_LAYER_NAME_STR} ---\")\n",
    "#     target_module = get_module_by_name_str(model, TARGET_LAYER_NAME_STR)\n",
    "#     print(f\"Successfully accessed target layer of type: {type(target_module)}\")\n",
    "\n",
    "#     sparsity_before = calculate_sparsity(target_module, 'weight')\n",
    "#     print(f\"Sparsity of '{TARGET_LAYER_NAME_STR}.weight' BEFORE pruning: {sparsity_before:.2f}%\\n\")\n",
    "#     print(f\"--- Applying L1 unstructured pruning (amount={PRUNING_AMOUNT}) ---\")\n",
    "#     prune.l1_unstructured(target_module, name=\"weight\", amount=PRUNING_AMOUNT)\n",
    "\n",
    "#     print(\"Pruning hook has been applied.\")\n",
    "#     print(f\"The layer now has a 'weight_mask' and 'weight_orig' attribute.\")\n",
    "#     print(f\"\\n--- Making pruning permanent for '{TARGET_LAYER_NAME_STR}.weight' ---\")\n",
    "#     prune.remove(target_module, \"weight\")\n",
    "#     print(\"Pruning has been made permanent. The 'weight' attribute is now the sparse tensor.\")\n",
    "#     sparsity_after = calculate_sparsity(target_module, 'weight')\n",
    "#     print(f\"Sparsity of '{TARGET_LAYER_NAME_STR}.weight' AFTER pruning: {sparsity_after:.2f}%\\n\")\n",
    "    \n",
    "#     return model\n",
    "\n",
    "# model_prune = prune_model_weights(model_new,PRUNING_AMOUNT)\n",
    "# sample_texts = articles[:num_prediction]\n",
    "# generated, times = generate_headline(model_prune, tokenizer, sample_texts, device,MAX_NEW_TOKENS,\"True\")\n",
    "# report_metrics(times,\" Unsupervised pruning\")\n",
    "# evaluate_model(datasets,generated,num_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: meta-llama/Llama-3.2-1B\n",
      "Using device: cuda\n",
      "Using dtype: torch.bfloat16\n",
      "Loading tokenizer...\n",
      "Tokenizer loaded successfully.\n",
      "Loading model...\n",
      "Model loaded successfully and moved to device.\n",
      "Loaded 'strategic_pruned_model' model.\n",
      "Memory Footprint: 2357.13 MB\n"
     ]
    }
   ],
   "source": [
    "def get_module_by_name(model, module_name):\n",
    "    \"\"\"Access a submodule in a model using its string name.\"\"\"\n",
    "    names = module_name.split('.')\n",
    "    module = model\n",
    "    for name in names:\n",
    "        module = getattr(module, name)\n",
    "    return module\n",
    "def apply_pruning(model, layers_to_prune, amount, method):\n",
    "    \"\"\"Apply a specified pruning method to a list of layers.\"\"\"\n",
    "    parameters_to_prune = []\n",
    "    for layer_name in layers_to_prune:\n",
    "        try:\n",
    "            module = get_module_by_name(model, layer_name)\n",
    "            parameters_to_prune.append((module, 'weight'))\n",
    "        except AttributeError:\n",
    "            print(f\"Warning: Layer {layer_name} not found. Skipping.\")\n",
    "\n",
    "    if not parameters_to_prune:\n",
    "        print(\"No valid layers found to prune.\")\n",
    "        return\n",
    "\n",
    "    pruning_method_map = {\n",
    "        'l1_unstructured': prune.L1Unstructured,\n",
    "    }\n",
    "    \n",
    "    prune.global_unstructured(\n",
    "        parameters_to_prune,\n",
    "        pruning_method=pruning_method_map[method],\n",
    "        amount=amount,\n",
    "    )\n",
    "\n",
    "    # # Make the pruning permanent\n",
    "    # for module, param_name in parameters_to_prune:\n",
    "    #     prune.remove(module, param_name)\n",
    "    #print(f\"Applied '{method}' pruning with {amount*100:.0f}% sparsity to {len(parameters_to_prune)} layers.\")\n",
    "\n",
    "def get_model_memory_footprint(model):\n",
    "    \"\"\"Calculates and returns the model's memory footprint in MB.\"\"\"\n",
    "    mem_params = sum(param.nelement() * param.element_size() for param in model.parameters())\n",
    "    mem_bufs = sum(buf.nelement() * buf.element_size() for buf in model.buffers())\n",
    "    total_mem_bytes = mem_params + mem_bufs\n",
    "    return total_mem_bytes / (1024 ** 2) # Convert bytes to MB\n",
    "\n",
    "\n",
    "dtype = torch.bfloat16 if device == \"cuda\" and torch.cuda.is_bf16_supported() else torch.float32\n",
    "strategic_pruned_model,tokenizer = load_model(model_name=model_name,device=device)\n",
    "memory_baseline = get_model_memory_footprint(strategic_pruned_model)\n",
    "print(f\"Loaded '{'strategic_pruned_model'}' model.\")\n",
    "print(f\"Memory Footprint: {memory_baseline:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj']\n",
      "['model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj']\n",
      "['model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj']\n",
      "['model.layers.0.mlp.gate_proj', 'model.layers.0.mlp.up_proj', 'model.layers.0.mlp.down_proj', 'model.layers.1.mlp.gate_proj', 'model.layers.1.mlp.up_proj', 'model.layers.1.mlp.down_proj', 'model.layers.2.mlp.gate_proj', 'model.layers.2.mlp.up_proj', 'model.layers.2.mlp.down_proj', 'model.layers.3.mlp.gate_proj', 'model.layers.3.mlp.up_proj', 'model.layers.3.mlp.down_proj']\n"
     ]
    }
   ],
   "source": [
    "NUM_LAYERS_TO_TARGET = 4\n",
    "MLP_LAYERS = []\n",
    "for i in range(NUM_LAYERS_TO_TARGET):\n",
    "    MLP_LAYERS.extend([\n",
    "        f\"model.layers.{i}.mlp.gate_proj\",\n",
    "        f\"model.layers.{i}.mlp.up_proj\",\n",
    "        f\"model.layers.{i}.mlp.down_proj\"\n",
    "    ])\n",
    "    print(MLP_LAYERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_pruning(strategic_pruned_model,MLP_LAYERS,PRUNING_AMOUNT,'l1_unstructured')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are for:  Magnitude Unstructured prunings\n",
      "Avg Latency: 1.104s\n",
      "P99 Latency: 1.107s\n",
      "Throughput: 0.91 samples/sec\n",
      "Max GPU Memory: 4729.85 MB\n",
      "ROUGE Scores: {'rouge1': 0.06440349178782798, 'rouge2': 0.0027027027027027024, 'rougeL': 0.04832239714195846, 'rougeLsum': 0.05169932288826383}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.06440349178782798,\n",
       " 'rouge2': 0.0027027027027027024,\n",
       " 'rougeL': 0.04832239714195846,\n",
       " 'rougeLsum': 0.05169932288826383}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_texts = articles[:NUM_PREDICTION]\n",
    "generated, times = generate_headline(strategic_pruned_model, tokenizer, sample_texts, device,MAX_NEW_TOKENS,\"True\")\n",
    "report_metrics(times,\" Magnitude Unstructured pruning\")\n",
    "evaluate_model(datasets,generated,NUM_PREDICTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned up models and emptied CUDA cache.\n"
     ]
    }
   ],
   "source": [
    "# Clean up model from memory\n",
    "clean(strategic_pruned_model,tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quantization-header"
   },
   "source": [
    "# 5. Model Compression: Quantization\n",
    "\n",
    "**Your Task:** Quantization reduces the precision of model weights (e.g., from 16-bit to 4-bit), significantly cutting down memory usage and often speeding up inference. You will define a 4-bit quantization configuration and use it to load and evaluate a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quantization-code"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: meta-llama/Llama-3.2-1B\n",
      "Using device: cuda\n",
      "Using dtype: torch.bfloat16\n",
      "Loading tokenizer...\n",
      "Tokenizer loaded successfully.\n",
      "Loading model...\n",
      "Model loaded successfully and moved to device.\n",
      "Loaded 'baseline_name' model.\n",
      "Memory Footprint: 2357.13 MB\n"
     ]
    }
   ],
   "source": [
    "dtype = torch.float16 \n",
    "\n",
    "quantized_model,tokenizer = load_model(model_name=model_name,device=device)\n",
    "memory_footprints = {}\n",
    "memory_baseline = get_model_memory_footprint(quantized_model)\n",
    "memory_footprints[\"baseline_name\"] = f\"{memory_baseline:.2f} MB\"\n",
    "print(f\"Loaded '{'baseline_name'}' model.\")\n",
    "print(f\"Memory Footprint: {memory_baseline:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned up models and emptied CUDA cache.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "clean(quantized_model,tokenizer)\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "model_8bit = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name, \n",
    "        quantization_config=quantization_config, \n",
    "        device_map=\"auto\" # Recommended for bitsandbytes\n",
    "    )\n",
    "memory_8bit = get_model_memory_footprint(model_8bit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 'quant_8bit_name' model.\n",
      "Memory Footprint: 1429.13 MB\n"
     ]
    }
   ],
   "source": [
    "memory_footprints[\"quant_8bit_name\"] = f\"{memory_8bit:.2f} MB\"\n",
    "print(f\"Loaded '{'quant_8bit_name'}' model.\")\n",
    "print(f\"Memory Footprint: {memory_8bit:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sample_texts \u001b[38;5;241m=\u001b[39m articles[:NUM_PREDICTION]\n\u001b[0;32m----> 2\u001b[0m generated, times \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_headline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_8bit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mMAX_NEW_TOKENS\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m report_metrics(times,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Quantised 8bit model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m evaluate_model(datasets,generated,NUM_PREDICTION)\n",
      "Cell \u001b[0;32mIn[4], line 30\u001b[0m, in \u001b[0;36mgenerate_headline\u001b[0;34m(model, tokenizer, texts, device, max_length, use_cache)\u001b[0m\n\u001b[1;32m     28\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     29\u001b[0m start \u001b[38;5;241m=\u001b[39m get_time()\n\u001b[0;32m---> 30\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Baseline: no KV caching\u001b[39;49;00m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     35\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m end \u001b[38;5;241m=\u001b[39m get_time()\n\u001b[1;32m     37\u001b[0m latencies\u001b[38;5;241m.\u001b[39mappend(end \u001b[38;5;241m-\u001b[39m start)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/generation/utils.py:2564\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2561\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m generation_config\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[1;32m   2563\u001b[0m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[0;32m-> 2564\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2565\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2566\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2570\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2571\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2572\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2574\u001b[0m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[1;32m   2575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2576\u001b[0m     generation_config\u001b[38;5;241m.\u001b[39mreturn_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2577\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result\u001b[38;5;241m.\u001b[39mpast_key_values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_legacy_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2579\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/generation/utils.py:2784\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2781\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[0;32m-> 2784\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2785\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2786\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/utils/generic.py:918\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[0;32m--> 918\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    920\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:459\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Unpack[TransformersKwargs],\n\u001b[1;32m    441\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CausalLMOutputWithPast:\n\u001b[1;32m    442\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;124;03m    ```\"\"\"\u001b[39;00m\n\u001b[0;32m--> 459\u001b[0m     outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/utils/generic.py:1064\u001b[0m, in \u001b[0;36mcheck_model_inputs.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1061\u001b[0m                 monkey_patched_layers\u001b[38;5;241m.\u001b[39mappend((module, original_forward))\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1064\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m     kwargs_without_recordable \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:368\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, cache_position, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must specify exactly one of input_ids or inputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 368\u001b[0m     inputs_embeds: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mand\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    371\u001b[0m     past_key_values \u001b[38;5;241m=\u001b[39m DynamicCache(config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "sample_texts = articles[:NUM_PREDICTION]\n",
    "generated, times = generate_headline(model_8bit, tokenizer, sample_texts, device,MAX_NEW_TOKENS,\"True\")\n",
    "report_metrics(times,\" Quantised 8bit model\")\n",
    "evaluate_model(datasets,generated,NUM_PREDICTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned up models and emptied CUDA cache.\n"
     ]
    }
   ],
   "source": [
    "clean(model_8bit,tokenizer)\n",
    "quantization_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "model_4bit = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name, \n",
    "        quantization_config=quantization_config, \n",
    "        device_map=\"auto\" # Recommended for bitsandbytes\n",
    "    )\n",
    "memory_4bit = get_model_memory_footprint(model_4bit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 'quant_4bit_name' model.\n",
      "Memory Footprint: 965.13 MB\n"
     ]
    }
   ],
   "source": [
    "memory_footprints[\"quant_4bit_name\"] = f\"{memory_4bit:.2f} MB\"\n",
    "print(f\"Loaded '{'quant_4bit_name'}' model.\")\n",
    "print(f\"Memory Footprint: {memory_4bit:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sample_texts \u001b[38;5;241m=\u001b[39m articles[:NUM_PREDICTION]\n\u001b[0;32m----> 2\u001b[0m generated, times \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_headline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_4bit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43mMAX_NEW_TOKENS\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m report_metrics(times,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Quantised 4bit model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m evaluate_model(datasets,generated,NUM_PREDICTION)\n",
      "Cell \u001b[0;32mIn[4], line 30\u001b[0m, in \u001b[0;36mgenerate_headline\u001b[0;34m(model, tokenizer, texts, device, max_length, use_cache)\u001b[0m\n\u001b[1;32m     28\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     29\u001b[0m start \u001b[38;5;241m=\u001b[39m get_time()\n\u001b[0;32m---> 30\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Baseline: no KV caching\u001b[39;49;00m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     35\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m end \u001b[38;5;241m=\u001b[39m get_time()\n\u001b[1;32m     37\u001b[0m latencies\u001b[38;5;241m.\u001b[39mappend(end \u001b[38;5;241m-\u001b[39m start)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/generation/utils.py:2564\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2561\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m generation_config\u001b[38;5;241m.\u001b[39muse_cache\n\u001b[1;32m   2563\u001b[0m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[0;32m-> 2564\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2565\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2566\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2570\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2571\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2572\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2574\u001b[0m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[1;32m   2575\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2576\u001b[0m     generation_config\u001b[38;5;241m.\u001b[39mreturn_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2577\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2578\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result\u001b[38;5;241m.\u001b[39mpast_key_values, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_legacy_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2579\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/generation/utils.py:2784\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2781\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_prefill:\n\u001b[0;32m-> 2784\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   2785\u001b[0m     is_prefill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2786\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/utils/generic.py:918\u001b[0m, in \u001b[0;36mcan_return_tuple.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m return_dict_passed\n\u001b[0;32m--> 918\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    920\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mto_tuple()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:459\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Unpack[TransformersKwargs],\n\u001b[1;32m    441\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CausalLMOutputWithPast:\n\u001b[1;32m    442\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;124;03m    ```\"\"\"\u001b[39;00m\n\u001b[0;32m--> 459\u001b[0m     outputs: BaseModelOutputWithPast \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    468\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    470\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/utils/generic.py:1064\u001b[0m, in \u001b[0;36mcheck_model_inputs.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1061\u001b[0m                 monkey_patched_layers\u001b[38;5;241m.\u001b[39mappend((module, original_forward))\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1064\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[1;32m   1066\u001b[0m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m     kwargs_without_recordable \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:368\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, cache_position, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must specify exactly one of input_ids or inputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 368\u001b[0m     inputs_embeds: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mand\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    371\u001b[0m     past_key_values \u001b[38;5;241m=\u001b[39m DynamicCache(config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/modules/sparse.py:190\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/torch/nn/functional.py:2551\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2546\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2548\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2549\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2550\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:3 and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)"
     ]
    }
   ],
   "source": [
    "sample_texts = articles[:NUM_PREDICTION]\n",
    "generated, times = generate_headline(model_4bit, tokenizer, sample_texts, device,MAX_NEW_TOKENS,\"True\")\n",
    "report_metrics(times,\" Quantised 4bit model\")\n",
    "evaluate_model(datasets,generated,NUM_PREDICTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned up models and emptied CUDA cache.\n"
     ]
    }
   ],
   "source": [
    "clean(model_4bit,tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "distributed-header"
   },
   "source": [
    "# 6. Distributed Inference (Multi-GPU)\n",
    "\n",
    "**Your Task:** If you have multiple GPUs, you can split the model across them to reduce the memory burden on a single GPU and potentially improve latency. We will explore two common techniques: Tensor Parallelism and Pipeline Parallelism.\n",
    "\n",
    "*Note: This section requires a multi-GPU environment.*\n",
    "\n",
    "### Tensor Parallelism\n",
    "Tensor parallelism splits individual model layers (the tensors) across multiple GPUs. Operations like matrix multiplications are executed in parallel on different GPUs, and the results are aggregated. This is highly effective for reducing the memory footprint of very large layers. The `accelerate` library can handle this automatically via `device_map=\"auto\"`.\n",
    "\n",
    "### Pipeline Parallelism\n",
    "Pipeline parallelism assigns entire layers or blocks of layers to different GPUs, creating a sequence or \"pipeline\" that the data flows through. For example, layers 1-10 run on GPU 0, layers 11-20 run on GPU 1, and so on. This is useful for very deep models where even a single layer might be too large for one GPU after tensor parallelism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.6.0+cu124\n",
      "CUDA is available: True\n",
      "Number of GPUs available: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "#print(f\"DeepSpeed version: {deepspeed.__version__}\")\n",
    "print(f\"CUDA is available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "    if torch.cuda.device_count() < 4:\n",
    "        print(\"!! WARNING: This demo is designed for 4 GPUs. It may not run correctly. !!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: cuda_home: command not found\n"
     ]
    }
   ],
   "source": [
    "!cuda_home = \"/usr/local/cuda-12.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;36mcuda\u001b[0m@\n",
      "\u001b[01;34mcuda-12.1\u001b[0m/\n",
      "\u001b[01;34mcuda-12.2\u001b[0m/\n",
      "\u001b[01;34mcuda-12.3\u001b[0m/\n",
      "\u001b[01;34mcuda-12.4\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls /usr/local/ | grep cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32m/usr/local/cuda-12.2/bin/nvcc\u001b[0m*\n"
     ]
    }
   ],
   "source": [
    "ls /usr/local/cuda-12.2/bin/nvcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2023 NVIDIA Corporation\n",
      "Built on Mon_Apr__3_17:16:06_PDT_2023\n",
      "Cuda compilation tools, release 12.1, V12.1.105\n",
      "Build cuda_12.1.r12.1/compiler.32688072_0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import subprocess\n",
    "\n",
    "# nvcc_path = subprocess.check_output([\"which\", \"nvcc\"], universal_newlines=True).strip()\n",
    "# output = subprocess.check_output([nvcc_path, \"-V\"], universal_newlines=True)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.6.0+cu118\n",
      "Uninstalling torch-2.6.0+cu118:\n",
      "  Successfully uninstalled torch-2.6.0+cu118\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip uninstall -y torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl (780.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m  \u001b[33m0:00:07\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (0.21.0+cu118)\n",
      "Requirement already satisfied: torchaudio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (2025.9.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m216.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m180.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m242.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m245.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m272.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m197.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==3.1.0 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m163.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (1.26.4)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp310-cp310-linux_x86_64.whl (7.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m203.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torchvision) (11.3.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp310-cp310-linux_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m196.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
      "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
      "\u001b[2K  Attempting uninstall: triton\n",
      "\u001b[2K    Found existing installation: triton 3.2.0\n",
      "\u001b[2K    Uninstalling triton-3.2.0:\n",
      "\u001b[2K      Successfully uninstalled triton-3.2.0\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━\u001b[0m \u001b[32m 0/13\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.4.1273\u001b[0m [triton]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.4.127:━\u001b[0m \u001b[32m 0/13\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.4.127/13\u001b[0m [triton]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12\u001b[0m \u001b[32m 0/13\u001b[0m [triton]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.3.1.170[triton]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.3.1.170:\u001b[32m 0/13\u001b[0m [triton]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.3.1.170━━━━\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.5.147\u001b[0m \u001b[32m 2/13\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.5.147:━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/13\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.5.147━━\u001b[0m \u001b[32m 3/13\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/13\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.2.1.3━━━\u001b[0m \u001b[32m 3/13\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.2.1.3:━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/13\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.2.1.3━━━━━\u001b[0m \u001b[32m 3/13\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/13\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.4.127 \u001b[32m 4/13\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.4.127:━━━━━━━━━━━\u001b[0m \u001b[32m 4/13\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.4.1270m \u001b[32m 4/13\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/13\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.4.1270m \u001b[32m 4/13\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.4.127:━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/13\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.4.127\u001b[0m \u001b[32m 4/13\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/13\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.4.1270m \u001b[32m 6/13\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.4.127:━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/13\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.4.127\u001b[0m \u001b[32m 6/13\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/13\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.4.5.8━━\u001b[0m \u001b[32m 7/13\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.4.5.8:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/13\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.4.5.8━━━━\u001b[0m \u001b[32m 7/13\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu120m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/13\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.6.1.9\u001b[0m \u001b[32m 8/13\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.6.1.9:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/13\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.6.1.9━━\u001b[0m \u001b[32m 8/13\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: torchvision━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m10/13\u001b[0m [torch]-cusolver-cu12]\n",
      "\u001b[2K    Found existing installation: torchvision 0.21.0+cu118━━━━━\u001b[0m \u001b[32m10/13\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling torchvision-0.21.0+cu118:m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m10/13\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.21.0+cu118━━━━━━━\u001b[0m \u001b[32m10/13\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchaudio━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m11/13\u001b[0m [torchvision]\n",
      "\u001b[2K    Found existing installation: torchaudio 2.6.0+cu118m━━━━━━\u001b[0m \u001b[32m11/13\u001b[0m [torchvision]\n",
      "\u001b[2K    Uninstalling torchaudio-2.6.0+cu118:m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m11/13\u001b[0m [torchvision]\n",
      "\u001b[2K      Successfully uninstalled torchaudio-2.6.0+cu11890m━━━━━━\u001b[0m \u001b[32m11/13\u001b[0m [torchvision]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/13\u001b[0m [torchaudio]3\u001b[0m [torchaudio]\n",
      "\u001b[1A\u001b[2KSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nvtx-cu12-12.1.105 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export CUDA_HOME=/usr/local/cuda-12.2\n",
    "# !export PATH=$CUDA_HOME/bin:$PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# cuda_home = os.environ.get(\"CUDA_HOME\", \"/usr/local/cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo ln -s /usr/local/cuda-12.2 /usr/local/cuda-11.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepspeed\n",
      "  Using cached deepspeed-0.18.1.tar.gz (1.6 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting einops (from deepspeed)\n",
      "  Downloading einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting hjson (from deepspeed)\n",
      "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: msgpack in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepspeed) (1.1.2)\n",
      "Collecting ninja (from deepspeed)\n",
      "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepspeed) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepspeed) (24.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepspeed) (7.1.0)\n",
      "Requirement already satisfied: py-cpuinfo in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepspeed) (9.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepspeed) (2.12.0)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepspeed) (2.5.1+cu121)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepspeed) (4.67.1)\n",
      "Requirement already satisfied: nvidia-ml-py in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from deepspeed) (13.580.82)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (2.41.1)\n",
      "Requirement already satisfied: typing-extensions>=4.14.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (4.15.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed) (0.4.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->deepspeed) (3.20.0)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->deepspeed) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->deepspeed) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->deepspeed) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->deepspeed) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->deepspeed) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->deepspeed) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->deepspeed) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->deepspeed) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->deepspeed) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->deepspeed) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->deepspeed) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->deepspeed) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->deepspeed) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->deepspeed) (12.1.105)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->deepspeed) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from torch->deepspeed) (1.13.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed) (12.4.127)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sympy==1.13.1->torch->deepspeed) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jinja2->torch->deepspeed) (3.0.3)\n",
      "Downloading einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
      "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
      "Building wheels for collected packages: deepspeed\n",
      "\u001b[33m  DEPRECATION: Building 'deepspeed' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'deepspeed'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for deepspeed (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for deepspeed: filename=deepspeed-0.18.1-py3-none-any.whl size=1764316 sha256=4b0c80028825a857447d8d772952be7fd53d5e4480e8ccebfea761c99594b7dc\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/ca/6b/76/ffb4c8190bbb957a36962a511169933d97e54ac70612b16d02\n",
      "Successfully built deepspeed\n",
      "Installing collected packages: hjson, ninja, einops, deepspeed\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4/4\u001b[0m [deepspeed]/4\u001b[0m [deepspeed]\n",
      "\u001b[1A\u001b[2KSuccessfully installed deepspeed-0.18.1 einops-0.8.1 hjson-3.1.0 ninja-1.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from evaluate import load as load_metric\n",
    "\n",
    "# Load ROUGE once\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "def generate_and_benchmark(model, tokenizer, texts, references, label=\"KV-Caching\", use_cache=True, assistant_model=None):\n",
    "    predictions = []\n",
    "    latencies = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(model.device)\n",
    "            start = time.time()\n",
    "            outputs = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=30,\n",
    "                use_cache=use_cache,\n",
    "                do_sample=False,\n",
    "                assistant_model=assistant_model  # Optional for speculative decoding\n",
    "            )\n",
    "            end = time.time()https://onedrive.live.com/?id=root&cid=9A4AB227FDDF5F95&qt=mru\n",
    "            latencies.append(end - start)\n",
    "            pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            predictions.append(pred)\n",
    "\n",
    "    # Compute metrics\n",
    "    avg_latency = sum(latencies) / len(latencies)\n",
    "    p99_latency = sorted(latencies)[int(0.99 * len(latencies))]\n",
    "    throughput = len(latencies) / sum(latencies)\n",
    "    gpu_memory = torch.cuda.max_memory_allocated() / (1024 ** 2)\n",
    "    rouge_scores = rouge.compute(predictions=predictions, references=references)\n",
    "\n",
    "    print(f\"\\n[{label}]\")\n",
    "    print(f\"Avg Latency: {avg_latency:.3f}s\")\n",
    "    print(f\"P99 Latency: {p99_latency:.3f}s\")\n",
    "    print(f\"Throughput: {throughput:.2f} samples/sec\")\n",
    "    print(f\"Max GPU Memory: {gpu_memory:.2f} MB\")\n",
    "    print(f\"ROUGE-1: {rouge_scores['rouge1'].mid.fmeasure:.4f}\")\n",
    "    print(f\"ROUGE-2: {rouge_scores['rouge2'].mid.fmeasure:.4f}\")\n",
    "    print(f\"ROUGE-L: {rouge_scores['rougeL'].mid.fmeasure:.4f}\")\n",
    "\n",
    "    return {\n",
    "        \"Variant\": label,\n",
    "        \"Avg Latency (s)\": round(avg_latency, 3),\n",
    "        \"P99 Latency (s)\": round(p99_latency, 3),\n",
    "        \"Throughput (samples/sec)\": round(throughput, 2),\n",
    "        \"Max GPU Memory (MB)\": round(gpu_memory, 2),\n",
    "        \"ROUGE-1\": round(rouge_scores[\"rouge1\"].mid.fmeasure, 4),\n",
    "        \"ROUGE-2\": round(rouge_scores[\"rouge2\"].mid.fmeasure, 4),\n",
    "        \"ROUGE-L\": round(rouge_scores[\"rougeL\"].mid.fmeasure, 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "distributed-code",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Check for multi-GPU environment and evaluate with Tensor Parallelism.\n",
    "# The `device_map=\"auto\"` in your `load_model` function should automatically apply this.\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.2-1B\")\n",
    "\n",
    "# Load model with automatic device mapping\n",
    "model_tp = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-3.2-1B\",\n",
    "    device_map=\"auto\",  # Tensor parallelism\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "model_tp.eval()\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model_tp.config.pad_token_id = model_tp.config.eos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are for:  Tensor Parallels\n",
      "Avg Latency: 1.427s\n",
      "P99 Latency: 1.429s\n",
      "Throughput: 0.70 samples/sec\n",
      "Max GPU Memory: 3605.27 MB\n",
      "ROUGE Scores: {'rouge1': 0.06903897053835856, 'rouge2': 0.005234348272322956, 'rougeL': 0.05600198089488176, 'rougeLsum': 0.05687975724695431}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.06903897053835856,\n",
       " 'rouge2': 0.005234348272322956,\n",
       " 'rougeL': 0.05600198089488176,\n",
       " 'rougeLsum': 0.05687975724695431}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_texts = articles[:NUM_PREDICTION]\n",
    "generated, times = generate_headline(model_tp, tokenizer, sample_texts, device,MAX_NEW_TOKENS,\"True\")\n",
    "report_metrics(times,\" Tensor Parallel\")\n",
    "evaluate_model(datasets,generated,NUM_PREDICTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# references = [item for item in datasets[:NUM_PREDICTION]['headline']]\n",
    "# results_tp = generate_and_benchmark(\n",
    "#     model=model_tp,\n",
    "#     tokenizer=tokenizer,\n",
    "#     texts=sample_texts,\n",
    "#     references=references,\n",
    "#     label=\"Tensor Parallel\",\n",
    "#     use_cache=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pipeline-code"
   },
   "outputs": [],
   "source": [
    "# TODO: Evaluate with Pipeline Parallelism.\n",
    "# This is more advanced and may require manually defining a device_map to assign\n",
    "# different layers of the model to different GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "speculative-header"
   },
   "source": [
    "# 7. Advanced Decoding: Speculative Decoding\n",
    "\n",
    "**Your Task:** Speculative decoding uses a smaller, faster \"draft\" model to generate several candidate tokens. A larger, more accurate \"target\" model then verifies these tokens in a single forward pass. This can significantly speed up generation if the draft model is a good predictor. You will load a larger target model and a smaller draft model, benchmark the target model alone, and then benchmark it with assistance from the draft model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "speculative-code"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are for:  Pipeline Parallels\n",
      "Avg Latency: 1.431s\n",
      "P99 Latency: 1.437s\n",
      "Throughput: 0.70 samples/sec\n",
      "Max GPU Memory: 4222.28 MB\n",
      "ROUGE Scores: {'rouge1': 0.06903897053835856, 'rouge2': 0.005234348272322956, 'rougeL': 0.05600198089488176, 'rougeLsum': 0.05687975724695431}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.06903897053835856,\n",
       " 'rouge2': 0.005234348272322956,\n",
       " 'rougeL': 0.05600198089488176,\n",
       " 'rougeLsum': 0.05687975724695431}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_texts = articles[:NUM_PREDICTION]\n",
    "generated, times = generate_headline(model_pp, tokenizer, sample_texts, device,MAX_NEW_TOKENS,\"True\")\n",
    "report_metrics(times,\" Pipeline Parallel\")\n",
    "evaluate_model(datasets,generated,NUM_PREDICTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "134593b4f12347d5b35b1a9a665f1120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fefea8841ce1478588cc5af0b604248a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b9a5d802eff4629b924f3e45c19700d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab0a8d0d4f64aadbaa9e17785cff28e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/826 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d866a65354674caab941748c11f3bac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c0f6153312b47beafe3ab31c911a604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb803059afe847cc8532d36932df3392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0edf5c9845744148a8c59ba144741676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403023b73be74915b44767ea70709cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9c0d3150af4f7ebf1118f0b7231cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82f8d59da6e4d36863aef31bafd9d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4774d9aa098b40dc830df9cdf7548655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/185 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B\")\n",
    "\n",
    "# Load Draft Model (1B)\n",
    "draft_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-3.2-1B\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "draft_model.eval()\n",
    "\n",
    "# Load Target Model (7B)\n",
    "target_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"meta-llama/Llama-3.1-8B\",\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "target_model.eval()\n",
    "\n",
    "# Load ROUGE\n",
    "rouge = load_metric(\"rouge\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_speculative_decoding(texts, references, max_new_tokens=30):\n",
    "    predictions = []\n",
    "    latencies = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for text in texts:\n",
    "            inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(target_model.device)\n",
    "            start = time.time()\n",
    "            outputs = target_model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                use_cache=True,\n",
    "                do_sample=False,\n",
    "                assistant_model=draft_model  # Enables speculative decoding\n",
    "            )\n",
    "            end = time.time()\n",
    "            latencies.append(end - start)\n",
    "            pred = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            predictions.append(pred)\n",
    "\n",
    "    # Metrics\n",
    "    avg_latency = sum(latencies) / len(latencies)\n",
    "    p99_latency = sorted(latencies)[int(0.99 * len(latencies))]\n",
    "    throughput = len(latencies) / sum(latencies)\n",
    "    gpu_memory = torch.cuda.max_memory_allocated() / (1024 ** 2)\n",
    "    rouge_scores = rouge.compute(predictions=predictions, references=references)\n",
    "\n",
    "    print(f\"\\n[Speculative Decoding]\")\n",
    "    print(f\"Avg Latency: {avg_latency:.3f}s\")\n",
    "    print(f\"P99 Latency: {p99_latency:.3f}s\")\n",
    "    print(f\"Throughput: {throughput:.2f} samples/sec\")\n",
    "    print(f\"Max GPU Memory: {gpu_memory:.2f} MB\")\n",
    "    print(\"ROUGE Scores:\", rouge_scores)\n",
    "    \n",
    "\n",
    "    return {\n",
    "        \"Variant\": \"Speculative Decoding\",\n",
    "        \"Avg Latency (s)\": round(avg_latency, 3),\n",
    "        \"P99 Latency (s)\": round(p99_latency, 3),\n",
    "        \"Throughput (samples/sec)\": round(throughput, 2),\n",
    "        \"Max GPU Memory (MB)\": round(gpu_memory, 2)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_target_only(texts, references):\n",
    "    return generate_and_benchmark(\n",
    "        model=target_model,\n",
    "        tokenizer=tokenizer,\n",
    "        texts=texts,\n",
    "        references=references,\n",
    "        label=\"Target Model Only\",\n",
    "        use_cache=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Speculative Decoding]\n",
      "Avg Latency: 2.588s\n",
      "P99 Latency: 4.107s\n",
      "Throughput: 0.39 samples/sec\n",
      "Max GPU Memory: 7997.36 MB\n",
      "ROUGE Scores: {'rouge1': 0.10497653392172682, 'rouge2': 0.013333333333333332, 'rougeL': 0.08647341113848431, 'rougeLsum': 0.08954642064636534}\n"
     ]
    }
   ],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        model_tp.config.pad_token_id = model_tp.config.eos_token_id\n",
    "\n",
    "\n",
    "sample_texts = articles[:NUM_PREDICTION]\n",
    "references = [item for item in datasets[:NUM_PREDICTION]['headline']]\n",
    "results_speculative = run_speculative_decoding(sample_texts, references)\n",
    "# generated, times = generate_headline(model_tp, tokenizer, sample_texts, device,MAX_NEW_TOKENS,\"True\")\n",
    "# report_metrics(times,\" Tensor Parallel\")\n",
    "# evaluate_model(datasets,generated,NUM_PREDICTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_target_only(texts, references):\n",
    "    return generate_and_benchmark(\n",
    "        model=target_model,\n",
    "        tokenizer=tokenizer,\n",
    "        texts=texts,\n",
    "        references=references,\n",
    "        label=\"Target Model Only\",\n",
    "        use_cache=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are for:  target_models\n",
      "Avg Latency: 3.475s\n",
      "P99 Latency: 3.480s\n",
      "Throughput: 0.29 samples/sec\n",
      "Max GPU Memory: 7997.36 MB\n",
      "ROUGE Scores: {'rouge1': 0.09330471222564926, 'rouge2': 0.010526315789473684, 'rougeL': 0.07611139601895961, 'rougeLsum': 0.08449443301989853}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.09330471222564926,\n",
       " 'rouge2': 0.010526315789473684,\n",
       " 'rougeL': 0.07611139601895961,\n",
       " 'rougeLsum': 0.08449443301989853}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_texts = articles[:NUM_PREDICTION]\n",
    "generated, times = generate_headline(target_model, tokenizer, sample_texts, device,MAX_NEW_TOKENS,\"True\")\n",
    "report_metrics(times,\" target_model\")\n",
    "evaluate_model(datasets,generated,NUM_PREDICTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "report-header"
   },
   "source": [
    "# 8. Final Report and Analysis\n",
    "\n",
    "**Your Task:** Consolidate your findings into a summary report. \n",
    "\n",
    "1.  Fill in the Markdown table below with the **Latency**, **Throughput**, and **ROUGE scores** for each optimization technique you implemented.\n",
    "2. Compile the final Project Report in PDF format:\n",
    "    *   Document the entire process, detailing the methodology, techniques, and libraries used.\n",
    "    *   Present the final benchmark results clearly.\n",
    "    *   Provide a thorough analysis of the trade-offs between performance, resources, and quality for each optimization step.\n",
    "    *   Conclude with recommendations for the most effective optimization strategy for this specific headline generation task, supported by your data.\n",
    "\n",
    "Some example questions for discussing the trade-offs:\n",
    "    *   Which method gave the best performance improvement?\n",
    "    *   Did any methods significantly hurt the ROUGE score (quality)?\n",
    "    *   Which optimization would you recommend for deployment in a production environment at the news portal, and why? Consider factors like cost, complexity, and performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "report-table"
   },
   "source": [
    "## Performance Comparison\n",
    "\n",
    "| Optimization Technique | Mean Latency (s) | Throughput (tokens/s) | ROUGE-1 Score |\n",
    "|--------------------------|------------------|-----------------------|---------------|\n",
    "| Baseline (No Cache)      | TODO             | TODO                  | TODO          |\n",
    "| KV Caching               | TODO             | TODO                  | TODO          |\n",
    "| Pruning (30%)            | TODO             | TODO                  | TODO          |\n",
    "| Quantization (4-bit)     | TODO             | TODO                  | TODO          |\n",
    "| Tensor Parallelism       | TODO             | TODO                  | TODO          |\n",
    "| Pipeline Parallelism     | TODO             | TODO                  | TODO          |\n",
    "| Speculative Decoding     | TODO             | TODO                  | TODO          |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
